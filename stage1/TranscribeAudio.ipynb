{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnFL-wB4owPL",
        "outputId": "7cd3252f-c852-4876-a8d5-76004fb7d1a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-gyknos3g\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-gyknos3g\n",
            "  Resolved https://github.com/openai/whisper.git to commit 7858aa9c08d98f75575035ecd6481f462d66ca27\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.26.0)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.16.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper==20230124) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.24.3)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Hit:6 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "27 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-510\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 27 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"1.mp3\" --model medium.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkiBqWPip0w0",
        "outputId": "fb4f9688-2355-4ec2-ac70-7a750c3c3ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcmalloc: large alloc 1528012800 bytes == 0xbb88000 @  0x7fda6bbf3680 0x7fda6bc14824 0x5f97c1 0x649901 0x5c43c6 0x4f327e 0x64e618 0x505163 0x56bbe1 0x5f5ee6 0x56bab6 0x569d8a 0x5f60c3 0x56cc92 0x5f5ee6 0x56bab6 0x569d8a 0x68e267 0x67d9b1 0x67da2f 0x67dad1 0x67fbf7 0x6b8082 0x6b840d 0x7fda6b9f2083 0x5faa2e\n",
            "[00:00.000 --> 00:06.240]  In my opinion in the future people will read more books than they do today and\n",
            "[00:06.240 --> 00:12.580]  there are two reasons and the first one is that although the you know the books\n",
            "[00:12.580 --> 00:18.400]  in the paper would be less frequent than we do today because of the protection of\n",
            "[00:18.400 --> 00:24.160]  the environment those policies regulation regulates we to use less\n",
            "[00:24.160 --> 00:31.520]  paper and so we switch those paper to electronic devices and the other reasons\n",
            "[00:31.520 --> 00:39.320]  that as the error changes what is invariant is what we require the our\n",
            "[00:39.320 --> 00:45.720]  requirement of knowledge so as long as that requirement doesn't fade so we will\n",
            "[00:45.720 --> 00:54.360]  always have a requirement for books\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4_4aYrs0Lr9",
        "outputId": "e8b678c4-d0ba-4501-9175-050f3ae56c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: whisper\n",
            "       [-h]\n",
            "       [--model {tiny.en,tiny,base.en,base,small.en,small,medium.en,medium,large-v1,large-v2,large}]\n",
            "       [--model_dir MODEL_DIR]\n",
            "       [--device DEVICE]\n",
            "       [--output_dir OUTPUT_DIR]\n",
            "       [--output_format {txt,vtt,srt,tsv,json,all}]\n",
            "       [--verbose VERBOSE]\n",
            "       [--task {transcribe,translate}]\n",
            "       [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
            "       [--temperature TEMPERATURE]\n",
            "       [--best_of BEST_OF]\n",
            "       [--beam_size BEAM_SIZE]\n",
            "       [--patience PATIENCE]\n",
            "       [--length_penalty LENGTH_PENALTY]\n",
            "       [--suppress_tokens SUPPRESS_TOKENS]\n",
            "       [--initial_prompt INITIAL_PROMPT]\n",
            "       [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT]\n",
            "       [--fp16 FP16]\n",
            "       [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
            "       [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
            "       [--logprob_threshold LOGPROB_THRESHOLD]\n",
            "       [--no_speech_threshold NO_SPEECH_THRESHOLD]\n",
            "       [--threads THREADS]\n",
            "       audio\n",
            "       [audio ...]\n",
            "\n",
            "positional arguments:\n",
            "  audio\n",
            "    audio\n",
            "    file(s) to\n",
            "    transcribe\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  --model {tiny.en,tiny,base.en,base,small.en,small,medium.en,medium,large-v1,large-v2,large}\n",
            "    name of the\n",
            "    Whisper\n",
            "    model to\n",
            "    use\n",
            "    (default:\n",
            "    small)\n",
            "  --model_dir MODEL_DIR\n",
            "    the path to\n",
            "    save model\n",
            "    files; uses\n",
            "    ~/.cache/wh\n",
            "    isper by\n",
            "    default\n",
            "    (default:\n",
            "    None)\n",
            "  --device DEVICE\n",
            "    device to\n",
            "    use for\n",
            "    PyTorch\n",
            "    inference\n",
            "    (default:\n",
            "    cuda)\n",
            "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n",
            "    directory\n",
            "    to save the\n",
            "    outputs\n",
            "    (default:\n",
            "    .)\n",
            "  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n",
            "    format of\n",
            "    the output\n",
            "    file; if\n",
            "    not\n",
            "    specified,\n",
            "    all\n",
            "    available\n",
            "    formats\n",
            "    will be\n",
            "    produced\n",
            "    (default:\n",
            "    all)\n",
            "  --verbose VERBOSE\n",
            "    whether to\n",
            "    print out\n",
            "    the\n",
            "    progress\n",
            "    and debug\n",
            "    messages\n",
            "    (default:\n",
            "    True)\n",
            "  --task {transcribe,translate}\n",
            "    whether to\n",
            "    perform\n",
            "    X->X speech\n",
            "    recognition\n",
            "    ('transcrib\n",
            "    e') or\n",
            "    X->English\n",
            "    translation\n",
            "    ('translate\n",
            "    ')\n",
            "    (default:\n",
            "    transcribe)\n",
            "  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n",
            "    language\n",
            "    spoken in\n",
            "    the audio,\n",
            "    specify\n",
            "    None to\n",
            "    perform\n",
            "    language\n",
            "    detection\n",
            "    (default:\n",
            "    None)\n",
            "  --temperature TEMPERATURE\n",
            "    temperature\n",
            "    to use for\n",
            "    sampling\n",
            "    (default:\n",
            "    0)\n",
            "  --best_of BEST_OF\n",
            "    number of\n",
            "    candidates\n",
            "    when\n",
            "    sampling\n",
            "    with non-\n",
            "    zero\n",
            "    temperature\n",
            "    (default:\n",
            "    5)\n",
            "  --beam_size BEAM_SIZE\n",
            "    number of\n",
            "    beams in\n",
            "    beam\n",
            "    search,\n",
            "    only\n",
            "    applicable\n",
            "    when\n",
            "    temperature\n",
            "    is zero\n",
            "    (default:\n",
            "    5)\n",
            "  --patience PATIENCE\n",
            "    optional\n",
            "    patience\n",
            "    value to\n",
            "    use in beam\n",
            "    decoding,\n",
            "    as in https\n",
            "    ://arxiv.or\n",
            "    g/abs/2204.\n",
            "    05424, the\n",
            "    default\n",
            "    (1.0) is\n",
            "    equivalent\n",
            "    to conventi\n",
            "    onal beam\n",
            "    search\n",
            "    (default:\n",
            "    None)\n",
            "  --length_penalty LENGTH_PENALTY\n",
            "    optional\n",
            "    token\n",
            "    length\n",
            "    penalty\n",
            "    coefficient\n",
            "    (alpha) as\n",
            "    in https://\n",
            "    arxiv.org/a\n",
            "    bs/1609.081\n",
            "    44, uses\n",
            "    simple\n",
            "    length norm\n",
            "    alization\n",
            "    by default\n",
            "    (default:\n",
            "    None)\n",
            "  --suppress_tokens SUPPRESS_TOKENS\n",
            "    comma-\n",
            "    separated\n",
            "    list of\n",
            "    token ids\n",
            "    to suppress\n",
            "    during\n",
            "    sampling;\n",
            "    '-1' will\n",
            "    suppress\n",
            "    most\n",
            "    special\n",
            "    characters\n",
            "    except\n",
            "    common punc\n",
            "    tuations\n",
            "    (default:\n",
            "    -1)\n",
            "  --initial_prompt INITIAL_PROMPT\n",
            "    optional\n",
            "    text to\n",
            "    provide as\n",
            "    a prompt\n",
            "    for the\n",
            "    first\n",
            "    window.\n",
            "    (default:\n",
            "    None)\n",
            "  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n",
            "    if True,\n",
            "    provide the\n",
            "    previous\n",
            "    output of\n",
            "    the model\n",
            "    as a prompt\n",
            "    for the\n",
            "    next\n",
            "    window;\n",
            "    disabling\n",
            "    may make\n",
            "    the text in\n",
            "    consistent\n",
            "    across\n",
            "    windows,\n",
            "    but the\n",
            "    model\n",
            "    becomes\n",
            "    less prone\n",
            "    to getting\n",
            "    stuck in a\n",
            "    failure\n",
            "    loop\n",
            "    (default:\n",
            "    True)\n",
            "  --fp16 FP16\n",
            "    whether to\n",
            "    perform\n",
            "    inference\n",
            "    in fp16;\n",
            "    True by\n",
            "    default\n",
            "    (default:\n",
            "    True)\n",
            "  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n",
            "    temperature\n",
            "    to increase\n",
            "    when\n",
            "    falling\n",
            "    back when\n",
            "    the\n",
            "    decoding\n",
            "    fails to\n",
            "    meet either\n",
            "    of the\n",
            "    thresholds\n",
            "    below\n",
            "    (default:\n",
            "    0.2)\n",
            "  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n",
            "    if the gzip\n",
            "    compression\n",
            "    ratio is\n",
            "    higher than\n",
            "    this value,\n",
            "    treat the\n",
            "    decoding as\n",
            "    failed\n",
            "    (default:\n",
            "    2.4)\n",
            "  --logprob_threshold LOGPROB_THRESHOLD\n",
            "    if the\n",
            "    average log\n",
            "    probability\n",
            "    is lower\n",
            "    than this\n",
            "    value,\n",
            "    treat the\n",
            "    decoding as\n",
            "    failed\n",
            "    (default:\n",
            "    -1.0)\n",
            "  --no_speech_threshold NO_SPEECH_THRESHOLD\n",
            "    if the\n",
            "    probability\n",
            "    of the <|no\n",
            "    speech|>\n",
            "    token is\n",
            "    higher than\n",
            "    this value\n",
            "    AND the\n",
            "    decoding\n",
            "    has failed\n",
            "    due to `log\n",
            "    prob_thresh\n",
            "    old`,\n",
            "    consider\n",
            "    the segment\n",
            "    as silence\n",
            "    (default:\n",
            "    0.6)\n",
            "  --threads THREADS\n",
            "    number of\n",
            "    threads\n",
            "    used by\n",
            "    torch for\n",
            "    CPU\n",
            "    inference;\n",
            "    supercedes \n",
            "    MKL_NUM_THR\n",
            "    EADS/OMP_NU\n",
            "    M_THREADS\n",
            "    (default:\n",
            "    0)\n"
          ]
        }
      ]
    }
  ]
}